{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMD4/e7/D8njDBHuTtxZb7i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rashmi12305/credit-risk-model/blob/main/torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCJQqXXRSeGf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTMcW0AmkFk2",
        "outputId": "7eb5fdf9-c1bd-4c31-bae3-8a7005672d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CIFAR10',\n",
              " 'CIFAR100',\n",
              " 'CLEVRClassification',\n",
              " 'CREStereo',\n",
              " 'Caltech101',\n",
              " 'Caltech256',\n",
              " 'CarlaStereo',\n",
              " 'CelebA',\n",
              " 'Cityscapes',\n",
              " 'CocoCaptions',\n",
              " 'CocoDetection',\n",
              " 'Country211',\n",
              " 'DTD',\n",
              " 'DatasetFolder',\n",
              " 'EMNIST',\n",
              " 'ETH3DStereo',\n",
              " 'EuroSAT',\n",
              " 'FER2013',\n",
              " 'FGVCAircraft',\n",
              " 'FakeData',\n",
              " 'FallingThingsStereo',\n",
              " 'FashionMNIST',\n",
              " 'Flickr30k',\n",
              " 'Flickr8k',\n",
              " 'Flowers102',\n",
              " 'FlyingChairs',\n",
              " 'FlyingThings3D',\n",
              " 'Food101',\n",
              " 'GTSRB',\n",
              " 'HD1K',\n",
              " 'HMDB51',\n",
              " 'INaturalist',\n",
              " 'ImageFolder',\n",
              " 'ImageNet',\n",
              " 'Imagenette',\n",
              " 'InStereo2k',\n",
              " 'KMNIST',\n",
              " 'Kinetics',\n",
              " 'Kitti',\n",
              " 'Kitti2012Stereo',\n",
              " 'Kitti2015Stereo',\n",
              " 'KittiFlow',\n",
              " 'LFWPairs',\n",
              " 'LFWPeople',\n",
              " 'LSUN',\n",
              " 'LSUNClass',\n",
              " 'MNIST',\n",
              " 'Middlebury2014Stereo',\n",
              " 'MovingMNIST',\n",
              " 'Omniglot',\n",
              " 'OxfordIIITPet',\n",
              " 'PCAM',\n",
              " 'PhotoTour',\n",
              " 'Places365',\n",
              " 'QMNIST',\n",
              " 'RenderedSST2',\n",
              " 'SBDataset',\n",
              " 'SBU',\n",
              " 'SEMEION',\n",
              " 'STL10',\n",
              " 'SUN397',\n",
              " 'SVHN',\n",
              " 'SceneFlowStereo',\n",
              " 'Sintel',\n",
              " 'SintelStereo',\n",
              " 'StanfordCars',\n",
              " 'UCF101',\n",
              " 'USPS',\n",
              " 'VOCDetection',\n",
              " 'VOCSegmentation',\n",
              " 'VisionDataset',\n",
              " 'WIDERFace',\n",
              " '__all__',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__getattr__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_optical_flow',\n",
              " '_stereo_matching',\n",
              " 'caltech',\n",
              " 'celeba',\n",
              " 'cifar',\n",
              " 'cityscapes',\n",
              " 'clevr',\n",
              " 'coco',\n",
              " 'country211',\n",
              " 'dtd',\n",
              " 'eurosat',\n",
              " 'fakedata',\n",
              " 'fer2013',\n",
              " 'fgvc_aircraft',\n",
              " 'flickr',\n",
              " 'flowers102',\n",
              " 'folder',\n",
              " 'food101',\n",
              " 'gtsrb',\n",
              " 'hmdb51',\n",
              " 'imagenet',\n",
              " 'imagenette',\n",
              " 'inaturalist',\n",
              " 'kinetics',\n",
              " 'kitti',\n",
              " 'lfw',\n",
              " 'lsun',\n",
              " 'mnist',\n",
              " 'moving_mnist',\n",
              " 'omniglot',\n",
              " 'oxford_iiit_pet',\n",
              " 'pcam',\n",
              " 'phototour',\n",
              " 'places365',\n",
              " 'rendered_sst2',\n",
              " 'sbd',\n",
              " 'sbu',\n",
              " 'semeion',\n",
              " 'stanford_cars',\n",
              " 'stl10',\n",
              " 'sun397',\n",
              " 'svhn',\n",
              " 'ucf101',\n",
              " 'usps',\n",
              " 'utils',\n",
              " 'video_utils',\n",
              " 'vision',\n",
              " 'voc',\n",
              " 'widerface']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4proAO8j-Sg",
        "outputId": "230eb51d-d548-4f87-c6d9-60ce0539bc7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:07<00:00, 3584079.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 197815.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3675027.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 21231344.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxHZfN54j-Gs",
        "outputId": "eaadf772-76c9-4140-ed3c-6f18ab6899f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size = 64)\n",
        "test_loader = DataLoader(test_data, batch_size = 64)"
      ],
      "metadata": {
        "id": "R-HE7IjSkfD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in train_loader:\n",
        "  print(X.shape)\n",
        "  print(y.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJpBt3Y_krRw",
        "outputId": "4b23fe46-69ec-4f5e-dae2-116b78fec953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\""
      ],
      "metadata": {
        "id": "JZOhgs9klT1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NNfunction(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NNfunction().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLYGGXzak5mG",
        "outputId": "e2ea3fac-517d-405f-8f3a-8ca34814ed66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNfunction(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "f1aG5otule03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    loss=loss_fn(model(X), y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "nGhf-nm1li_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  loss, correct = 0, 0\n",
        "  for X, y in dataloader:\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    pred=model(X)\n",
        "    loss+= loss_fn(pred, y)\n",
        "    correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  loss /= num_batches\n",
        "  correct /= size\n",
        "  print(loss)\n",
        "  print(correct*100)"
      ],
      "metadata": {
        "id": "hMu4gPWll7hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 5\n",
        "for t in range(epoch):\n",
        "  print(f\"Epoch {t+1}\\n----------------------------------\")\n",
        "  train(train_loader, model, loss_fn, optimizer)\n",
        "  test(test_loader, model, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9oWSCvym0_g",
        "outputId": "be840a3e-db0b-486c-a6c5-7d4b9046aa30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "----------------------------------\n",
            "loss: 2.293453 [    0/60000]\n",
            "loss: 2.299369 [ 6400/60000]\n",
            "loss: 2.296298 [12800/60000]\n",
            "loss: 2.300451 [19200/60000]\n",
            "loss: 2.290045 [25600/60000]\n",
            "loss: 2.299598 [32000/60000]\n",
            "loss: 2.300323 [38400/60000]\n",
            "loss: 2.300098 [44800/60000]\n",
            "loss: 2.300018 [51200/60000]\n",
            "loss: 2.314382 [57600/60000]\n",
            "tensor(2.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "15.17\n",
            "Epoch 2\n",
            "----------------------------------\n",
            "loss: 2.293453 [    0/60000]\n",
            "loss: 2.299369 [ 6400/60000]\n",
            "loss: 2.296298 [12800/60000]\n",
            "loss: 2.300451 [19200/60000]\n",
            "loss: 2.290045 [25600/60000]\n",
            "loss: 2.299598 [32000/60000]\n",
            "loss: 2.300323 [38400/60000]\n",
            "loss: 2.300098 [44800/60000]\n",
            "loss: 2.300018 [51200/60000]\n",
            "loss: 2.314382 [57600/60000]\n",
            "tensor(2.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "15.17\n",
            "Epoch 3\n",
            "----------------------------------\n",
            "loss: 2.293453 [    0/60000]\n",
            "loss: 2.299369 [ 6400/60000]\n",
            "loss: 2.296298 [12800/60000]\n",
            "loss: 2.300451 [19200/60000]\n",
            "loss: 2.290045 [25600/60000]\n",
            "loss: 2.299598 [32000/60000]\n",
            "loss: 2.300323 [38400/60000]\n",
            "loss: 2.300098 [44800/60000]\n",
            "loss: 2.300018 [51200/60000]\n",
            "loss: 2.314382 [57600/60000]\n",
            "tensor(2.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "15.17\n",
            "Epoch 4\n",
            "----------------------------------\n",
            "loss: 2.293453 [    0/60000]\n",
            "loss: 2.299369 [ 6400/60000]\n",
            "loss: 2.296298 [12800/60000]\n",
            "loss: 2.300451 [19200/60000]\n",
            "loss: 2.290045 [25600/60000]\n",
            "loss: 2.299598 [32000/60000]\n",
            "loss: 2.300323 [38400/60000]\n",
            "loss: 2.300098 [44800/60000]\n",
            "loss: 2.300018 [51200/60000]\n",
            "loss: 2.314382 [57600/60000]\n",
            "tensor(2.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "15.17\n",
            "Epoch 5\n",
            "----------------------------------\n",
            "loss: 2.293453 [    0/60000]\n",
            "loss: 2.299369 [ 6400/60000]\n",
            "loss: 2.296298 [12800/60000]\n",
            "loss: 2.300451 [19200/60000]\n",
            "loss: 2.290045 [25600/60000]\n",
            "loss: 2.299598 [32000/60000]\n",
            "loss: 2.300323 [38400/60000]\n",
            "loss: 2.300098 [44800/60000]\n",
            "loss: 2.300018 [51200/60000]\n",
            "loss: 2.314382 [57600/60000]\n",
            "tensor(2.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "15.17\n"
          ]
        }
      ]
    }
  ]
}